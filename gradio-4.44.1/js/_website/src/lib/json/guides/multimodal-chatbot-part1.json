{"guide": {"name": "multimodal-chatbot-part1", "category": "custom-components", "pretty_category": "Custom Components", "guide_index": 8, "absolute_index": 39, "pretty_name": "Multimodal Chatbot Part1", "content": "# Build a Custom Multimodal Chatbot - Part 1\n\nThis is the first in a two part series where we build a custom Multimodal Chatbot component.\nIn part 1, we will modify the Gradio Chatbot component to display text and media files (video, audio, image) in the same message.\nIn part 2, we will build a custom Textbox component that will be able to send multimodal messages (text and media files) to the chatbot.\n\nYou can follow along with the author of this post as he implements the chatbot component in the following YouTube video!\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IVJkOHTBPn0?si=bs-sBv43X-RVA8ly\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n\nHere's a preview of what our multimodal chatbot component will look like:\n\n![MultiModal Chatbot](https://gradio-builds.s3.amazonaws.com/assets/MultimodalChatbot.png)\n\n\n## Part 1 - Creating our project\n\nFor this demo we will be tweaking the existing Gradio `Chatbot` component to display text and media files in the same message.\nLet's create a new custom component directory by templating off of the `Chatbot` component source code.\n\n```bash\ngradio cc create MultimodalChatbot --template Chatbot\n```\n\nAnd we're ready to go!\n            <p class='tip'>\n                <span class=\"inline-flex\" style=\"align-items: baseline\">\n                    <svg class=\"self-center w-5 h-5 mx-1\" xmlns=\"http://www.w3.org/2000/svg\" width=\"800px\" height=\"800px\" viewBox=\"0 0 24 24\" fill=\"currentColor\">\n                        <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M9.25 18.7089C9.25 18.2894 9.58579 17.9494 10 17.9494H14C14.4142 17.9494 14.75 18.2894 14.75 18.7089C14.75 19.1283 14.4142 19.4684 14 19.4684H10C9.58579 19.4684 9.25 19.1283 9.25 18.7089ZM9.91667 21.2405C9.91667 20.821 10.2525 20.481 10.6667 20.481H13.3333C13.7475 20.481 14.0833 20.821 14.0833 21.2405C14.0833 21.66 13.7475 22 13.3333 22H10.6667C10.2525 22 9.91667 21.66 9.91667 21.2405Z\"/>\n                        <path d=\"M7.41058 13.8283L8.51463 14.8807C8.82437 15.1759 9 15.5875 9 16.0182C9 16.6653 9.518 17.1899 10.157 17.1899H13.843C14.482 17.1899 15 16.6653 15 16.0182C15 15.5875 15.1756 15.1759 15.4854 14.8807L16.5894 13.8283C18.1306 12.3481 18.9912 10.4034 18.9999 8.3817L19 8.29678C19 4.84243 15.866 2 12 2C8.13401 2 5 4.84243 5 8.29678L5.00007 8.3817C5.00875 10.4034 5.86939 12.3481 7.41058 13.8283Z\"/>\n                    </svg>\n                <span><strong>Tip:</strong></span>\n                </span>\n                Make sure to modify the `Author` key in the `pyproject.toml` file.\n            </p>\n                \n\n## Part 2a - The backend data_model\n\nOpen up the `multimodalchatbot.py` file in your favorite code editor and let's get started modifying the backend of our component.\n\nThe first thing we will do is create the `data_model` of our component.\nThe `data_model` is the data format that your python component will receive and send to the javascript client running the UI.\nYou can read more about the `data_model` in the [backend guide](./backend).\n\nFor our component, each chatbot message will consist of two keys: a `text` key that displays the text message and an optional list of media files that can be displayed underneath the text.\n\nImport the `FileData` and `GradioModel` classes from `gradio.data_classes` and modify the existing `ChatbotData` class to look like the following:\n\n```python\nclass FileMessage(GradioModel):\n    file: FileData\n    alt_text: Optional[str] = None\n\n\nclass MultimodalMessage(GradioModel):\n    text: Optional[str] = None\n    files: Optional[List[FileMessage]] = None\n\n\nclass ChatbotData(GradioRootModel):\n    root: List[Tuple[Optional[MultimodalMessage], Optional[MultimodalMessage]]]\n\n\nclass MultimodalChatbot(Component):\n    ...\n    data_model = ChatbotData\n```\n\n            <p class='tip'>\n                <span class=\"inline-flex\" style=\"align-items: baseline\">\n                    <svg class=\"self-center w-5 h-5 mx-1\" xmlns=\"http://www.w3.org/2000/svg\" width=\"800px\" height=\"800px\" viewBox=\"0 0 24 24\" fill=\"currentColor\">\n                        <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M9.25 18.7089C9.25 18.2894 9.58579 17.9494 10 17.9494H14C14.4142 17.9494 14.75 18.2894 14.75 18.7089C14.75 19.1283 14.4142 19.4684 14 19.4684H10C9.58579 19.4684 9.25 19.1283 9.25 18.7089ZM9.91667 21.2405C9.91667 20.821 10.2525 20.481 10.6667 20.481H13.3333C13.7475 20.481 14.0833 20.821 14.0833 21.2405C14.0833 21.66 13.7475 22 13.3333 22H10.6667C10.2525 22 9.91667 21.66 9.91667 21.2405Z\"/>\n                        <path d=\"M7.41058 13.8283L8.51463 14.8807C8.82437 15.1759 9 15.5875 9 16.0182C9 16.6653 9.518 17.1899 10.157 17.1899H13.843C14.482 17.1899 15 16.6653 15 16.0182C15 15.5875 15.1756 15.1759 15.4854 14.8807L16.5894 13.8283C18.1306 12.3481 18.9912 10.4034 18.9999 8.3817L19 8.29678C19 4.84243 15.866 2 12 2C8.13401 2 5 4.84243 5 8.29678L5.00007 8.3817C5.00875 10.4034 5.86939 12.3481 7.41058 13.8283Z\"/>\n                    </svg>\n                <span><strong>Tip:</strong></span>\n                </span>\n                The `data_model`s are implemented using `Pydantic V2`. Read the documentation [here](https://docs.pydantic.dev/latest/).\n            </p>\n                \n\nWe've done the hardest part already!\n\n## Part 2b - The pre and postprocess methods\n\nFor the `preprocess` method, we will keep it simple and pass a list of `MultimodalMessage`s to the python functions that use this component as input. \nThis will let users of our component access the chatbot data with `.text` and `.files` attributes.\nThis is a design choice that you can modify in your implementation!\nWe can return the list of messages with the `root` property of the `ChatbotData` like so:\n\n```python\ndef preprocess(\n    self,\n    payload: ChatbotData | None,\n) -> List[MultimodalMessage] | None:\n    if payload is None:\n        return payload\n    return payload.root\n```\n\n            <p class='tip'>\n                <span class=\"inline-flex\" style=\"align-items: baseline\">\n                    <svg class=\"self-center w-5 h-5 mx-1\" xmlns=\"http://www.w3.org/2000/svg\" width=\"800px\" height=\"800px\" viewBox=\"0 0 24 24\" fill=\"currentColor\">\n                        <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M9.25 18.7089C9.25 18.2894 9.58579 17.9494 10 17.9494H14C14.4142 17.9494 14.75 18.2894 14.75 18.7089C14.75 19.1283 14.4142 19.4684 14 19.4684H10C9.58579 19.4684 9.25 19.1283 9.25 18.7089ZM9.91667 21.2405C9.91667 20.821 10.2525 20.481 10.6667 20.481H13.3333C13.7475 20.481 14.0833 20.821 14.0833 21.2405C14.0833 21.66 13.7475 22 13.3333 22H10.6667C10.2525 22 9.91667 21.66 9.91667 21.2405Z\"/>\n                        <path d=\"M7.41058 13.8283L8.51463 14.8807C8.82437 15.1759 9 15.5875 9 16.0182C9 16.6653 9.518 17.1899 10.157 17.1899H13.843C14.482 17.1899 15 16.6653 15 16.0182C15 15.5875 15.1756 15.1759 15.4854 14.8807L16.5894 13.8283C18.1306 12.3481 18.9912 10.4034 18.9999 8.3817L19 8.29678C19 4.84243 15.866 2 12 2C8.13401 2 5 4.84243 5 8.29678L5.00007 8.3817C5.00875 10.4034 5.86939 12.3481 7.41058 13.8283Z\"/>\n                    </svg>\n                <span><strong>Tip:</strong></span>\n                </span>\n                Learn about the reasoning behind the `preprocess` and `postprocess` methods in the [key concepts guide](./key-component-concepts)\n            </p>\n                \n\nIn the `postprocess` method we will coerce each message returned by the python function to be a `MultimodalMessage` class. \nWe will also clean up any indentation in the `text` field so that it can be properly displayed as markdown in the frontend.\n\nWe can leave the `postprocess` method as is and modify the `_postprocess_chat_messages`\n\n```python\ndef _postprocess_chat_messages(\n    self, chat_message: MultimodalMessage | dict | None\n) -> MultimodalMessage | None:\n    if chat_message is None:\n        return None\n    if isinstance(chat_message, dict):\n        chat_message = MultimodalMessage(**chat_message)\n    chat_message.text = inspect.cleandoc(chat_message.text or \"\")\n    for file_ in chat_message.files:\n        file_.file.mime_type = client_utils.get_mimetype(file_.file.path)\n    return chat_message\n```\n\nBefore we wrap up with the backend code, let's modify the `example_value` and `example_payload` method to return a valid dictionary representation of the `ChatbotData`:\n\n```python\ndef example_value(self) -> Any:\n    return [[{\"text\": \"Hello!\", \"files\": []}, None]]\n\ndef example_payload(self) -> Any:\n    return [[{\"text\": \"Hello!\", \"files\": []}, None]]\n```\n\nCongrats - the backend is complete!\n\n## Part 3a - The Index.svelte file\n\nThe frontend for the `Chatbot` component is divided into two parts - the `Index.svelte` file and the `shared/Chatbot.svelte` file.\nThe `Index.svelte` file applies some processing to the data received from the server and then delegates the rendering of the conversation to the `shared/Chatbot.svelte` file.\nFirst we will modify the `Index.svelte` file to apply processing to the new data type the backend will return.\n\nLet's begin by porting our custom types  from our python `data_model` to typescript.\nOpen `frontend/shared/utils.ts` and add the following type definitions at the top of the file:\n\n```ts\nexport type FileMessage = {\n\tfile: FileData;\n\talt_text?: string;\n};\n\n\nexport type MultimodalMessage = {\n\ttext: string;\n\tfiles?: FileMessage[];\n}\n```\n\nNow let's import them in `Index.svelte` and modify the type annotations for `value` and `_value`.\n\n```ts\nimport type { FileMessage, MultimodalMessage } from \"./shared/utils\";\n\nexport let value: [\n    MultimodalMessage | null,\n    MultimodalMessage | null\n][] = [];\n\nlet _value: [\n    MultimodalMessage | null,\n    MultimodalMessage | null\n][];\n```\n\nWe need to normalize each message to make sure each file has a proper URL to fetch its contents from.\nWe also need to format any embedded file links in the `text` key.\nLet's add a `process_message` utility function and apply it whenever the `value` changes.\n\n```ts\nfunction process_message(msg: MultimodalMessage | null): MultimodalMessage | null {\n    if (msg === null) {\n        return msg;\n    }\n    msg.text = redirect_src_url(msg.text);\n    msg.files = msg.files.map(normalize_messages);\n    return msg;\n}\n\n$: _value = value\n    ? value.map(([user_msg, bot_msg]) => [\n            process_message(user_msg),\n            process_message(bot_msg)\n        ])\n    : [];\n```\n\n## Part 3b - the Chatbot.svelte file\n\nLet's begin similarly to the `Index.svelte` file and let's first modify the type annotations.\nImport `Mulimodal` message at the top of the `<script>` section and use it to type the `value` and `old_value` variables.\n\n```ts\nimport type { MultimodalMessage } from \"./utils\";\n\nexport let value:\n    | [\n            MultimodalMessage | null,\n            MultimodalMessage | null\n        ][]\n    | null;\nlet old_value:\n    | [\n            MultimodalMessage | null,\n            MultimodalMessage | null\n        ][]\n    | null = null;\n```\n\nWe also need to modify the `handle_select` and `handle_like` functions:\n\n```ts\nfunction handle_select(\n    i: number,\n    j: number,\n    message: MultimodalMessage | null\n): void {\n    dispatch(\"select\", {\n        index: [i, j],\n        value: message\n    });\n}\n\nfunction handle_like(\n    i: number,\n    j: number,\n    message: MultimodalMessage | null,\n    liked: boolean\n): void {\n    dispatch(\"like\", {\n        index: [i, j],\n        value: message,\n        liked: liked\n    });\n}\n```\n\nNow for the fun part, actually rendering the text and files in the same message!\n\nYou should see some code like the following that determines whether a file or a markdown message should be displayed depending on the type of the message:\n\n```svelte\n{#if typeof message === \"string\"}\n    <Markdown\n        {message}\n        {latex_delimiters}\n        {sanitize_html}\n        {render_markdown}\n        {line_breaks}\n        on:load={scroll}\n    />\n{:else if message !== null && message.file?.mime_type?.includes(\"audio\")}\n    <audio\n        data-testid=\"chatbot-audio\"\n        controls\n        preload=\"metadata\"\n        ...\n```\n\nWe will modify this code to always display the text message and then loop through the files and display all of them that are present:\n\n```svelte\n<Markdown\n    message={message.text}\n    {latex_delimiters}\n    {sanitize_html}\n    {render_markdown}\n    {line_breaks}\n    on:load={scroll}\n/>\n{#each message.files as file, k}\n    {#if file !== null && file.file.mime_type?.includes(\"audio\")}\n        <audio\n            data-testid=\"chatbot-audio\"\n            controls\n            preload=\"metadata\"\n            src={file.file?.url}\n            title={file.alt_text}\n            on:play\n            on:pause\n            on:ended\n        />\n    {:else if message !== null && file.file?.mime_type?.includes(\"video\")}\n        <video\n            data-testid=\"chatbot-video\"\n            controls\n            src={file.file?.url}\n            title={file.alt_text}\n            preload=\"auto\"\n            on:play\n            on:pause\n            on:ended\n        >\n            <track kind=\"captions\" />\n        </video>\n    {:else if message !== null && file.file?.mime_type?.includes(\"image\")}\n        <img\n            data-testid=\"chatbot-image\"\n            src={file.file?.url}\n            alt={file.alt_text}\n        />\n    {:else if message !== null && file.file?.url !== null}\n        <a\n            data-testid=\"chatbot-file\"\n            href={file.file?.url}\n            target=\"_blank\"\n            download={window.__is_colab__\n                ? null\n                : file.file?.orig_name || file.file?.path}\n        >\n            {file.file?.orig_name || file.file?.path}\n        </a>\n    {:else if pending_message && j === 1}\n        <Pending {layout} />\n    {/if}\n{/each}\n```\n\nWe did it! \ud83c\udf89\n\n## Part 4 - The demo\n\nFor this tutorial, let's keep the demo simple and just display a static conversation between a hypothetical user and a bot.\nThis demo will show how both the user and the bot can send files. \nIn part 2 of this tutorial series we will build a fully functional chatbot demo!\n\nThe demo code will look like the following:\n\n```python\nimport gradio as gr\nfrom gradio_multimodalchatbot import MultimodalChatbot\nfrom gradio.data_classes import FileData\n\nuser_msg1 = {\"text\": \"Hello, what is in this image?\",\n             \"files\": [{\"file\": FileData(path=\"https://gradio-builds.s3.amazonaws.com/diffusion_image/cute_dog.jpg\")}]\n             }\nbot_msg1 = {\"text\": \"It is a very cute dog\",\n            \"files\": []}\n\nuser_msg2 = {\"text\": \"Describe this audio clip please.\",\n             \"files\": [{\"file\": FileData(path=\"cantina.wav\")}]}\nbot_msg2 = {\"text\": \"It is the cantina song from Star Wars\",\n            \"files\": []}\n\nuser_msg3 = {\"text\": \"Give me a video clip please.\",\n             \"files\": []}\nbot_msg3 = {\"text\": \"Here is a video clip of the world\",\n            \"files\": [{\"file\": FileData(path=\"world.mp4\")},\n                      {\"file\": FileData(path=\"cantina.wav\")}]}\n\nconversation = [[user_msg1, bot_msg1], [user_msg2, bot_msg2], [user_msg3, bot_msg3]]\n\nwith gr.Blocks() as demo:\n    MultimodalChatbot(value=conversation, height=800)\n\n\ndemo.launch()\n```\n\n            <p class='tip'>\n                <span class=\"inline-flex\" style=\"align-items: baseline\">\n                    <svg class=\"self-center w-5 h-5 mx-1\" xmlns=\"http://www.w3.org/2000/svg\" width=\"800px\" height=\"800px\" viewBox=\"0 0 24 24\" fill=\"currentColor\">\n                        <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M9.25 18.7089C9.25 18.2894 9.58579 17.9494 10 17.9494H14C14.4142 17.9494 14.75 18.2894 14.75 18.7089C14.75 19.1283 14.4142 19.4684 14 19.4684H10C9.58579 19.4684 9.25 19.1283 9.25 18.7089ZM9.91667 21.2405C9.91667 20.821 10.2525 20.481 10.6667 20.481H13.3333C13.7475 20.481 14.0833 20.821 14.0833 21.2405C14.0833 21.66 13.7475 22 13.3333 22H10.6667C10.2525 22 9.91667 21.66 9.91667 21.2405Z\"/>\n                        <path d=\"M7.41058 13.8283L8.51463 14.8807C8.82437 15.1759 9 15.5875 9 16.0182C9 16.6653 9.518 17.1899 10.157 17.1899H13.843C14.482 17.1899 15 16.6653 15 16.0182C15 15.5875 15.1756 15.1759 15.4854 14.8807L16.5894 13.8283C18.1306 12.3481 18.9912 10.4034 18.9999 8.3817L19 8.29678C19 4.84243 15.866 2 12 2C8.13401 2 5 4.84243 5 8.29678L5.00007 8.3817C5.00875 10.4034 5.86939 12.3481 7.41058 13.8283Z\"/>\n                    </svg>\n                <span><strong>Tip:</strong></span>\n                </span>\n                Change the filepaths so that they correspond to files on your machine. Also, if you are running in development mode, make sure the files are located in the top level of your custom component directory.\n            </p>\n                \n\n## Part 5 - Deploying and Conclusion\n\nLet's build and deploy our demo with `gradio cc build` and `gradio cc deploy`!\n\nYou can check out our component deployed to [HuggingFace Spaces](https://huggingface.co/spaces/freddyaboulton/gradio_multimodalchatbot) and all of the source code is available [here](https://huggingface.co/spaces/freddyaboulton/gradio_multimodalchatbot/tree/main/src).\n\nSee you in the next installment of this series!", "tags": [], "spaces": [], "url": "/guides/multimodal-chatbot-part1/", "contributor": null}}