
<script lang="ts">
    import {get_object} from "../../process_json.ts";
    import ParamTable from "$lib/components/ParamTable.svelte";
    import ShortcutTable from "$lib/components/ShortcutTable.svelte";
    import DemosSection from "$lib/components/DemosSection.svelte";
    import FunctionsSection from "$lib/components/FunctionsSection.svelte";
    import GuidesSection from "$lib/components/GuidesSection.svelte";
    import CopyButton from "$lib/components/CopyButton.svelte";
    import { style_formatted_text } from "$lib/text";

    let obj = get_object("chatbot");
</script>

<!--- Title -->
# {obj.name}

<!--- Usage -->
```python
gradio.Chatbot(¬∑¬∑¬∑)
```

<!-- Embedded Component -->
<div class="embedded-component">
<gradio-lite shared-worker>
import gradio as gr
with gr.Blocks() as demo:
    gr.Chatbot(value=[["Hello World","Hey Gradio!"],["‚ù§Ô∏è","üòç"],["üî•","ü§ó"]])
demo.launch()
</gradio-lite>
</div>

<!--- Description -->
### Description
## {@html style_formatted_text(obj.description)}

<!-- Behavior -->
### Behavior

The data format accepted by the Chatbot is dictated by the `type` parameter.
This parameter can take two values, `'tuples'` and `'messages'`.


If `type` is `'tuples'`, then the data sent to/from the chatbot will be a list of tuples.
The first element of each tuple is the user message and the second element is the bot's response.
Each element can be a string (markdown/html is supported),
a tuple (in which case the first element is a filepath that will be displayed in the chatbot),
or a gradio component (see the Examples section for more details).


If the `type` is `'messages'`, then the data sent to/from the chatbot will be a list of dictionaries
with `role` and `content` keys. This format is compliant with the format expected by most LLM APIs (HuggingChat, OpenAI, Claude).
The `role` key is either `'user'` or `'`assistant'` and the `content` key can be a string (markdown/html supported),
a `FileDataDict` (to represent a file that is displayed in the chatbot - documented below), or a gradio component.


For convenience, you can use the `ChatMessage` dataclass so that your text editor can give you autocomplete hints and typechecks.

```python
from gradio import ChatMessage

def generate_response(history):
    history.append(
        ChatMessage(role="assistant",
                    content="How can I help you?")
        )
    return history
```

Additionally, when `type` is `messages`, you can provide additional metadata regarding any tools used to generate the response.
This is useful for displaying the thought process of LLM agents. For example,

```python
def generate_response(history):
    history.append(
        ChatMessage(role="assistant",
                    content="The weather API says it is 20 degrees Celcius in New York.",
                    metadata={"title": "üõ†Ô∏è Used tool Weather API"})
        )
    return history
```

Would be displayed as following:

<img src="https://github.com/user-attachments/assets/c1514bc9-bc29-4af1-8c3f-cd4a7c2b217f" alt="Gradio chatbot tool display">


All of the types expected by the messages format are documented below:

```python
class MetadataDict(TypedDict):
    title: Union[str, None]

class FileDataDict(TypedDict):
    path: str  # server filepath
    url: NotRequired[Optional[str]]  # normalised server url
    size: NotRequired[Optional[int]]  # size in bytes
    orig_name: NotRequired[Optional[str]]  # original filename
    mime_type: NotRequired[Optional[str]]
    is_stream: NotRequired[bool]
    meta: dict[Literal["_type"], Literal["gradio.FileData"]]


class MessageDict(TypedDict):
    content: str | FileDataDict | Component
    role: Literal["user", "assistant", "system"]
    metadata: NotRequired[MetadataDict]


@dataclass
class Metadata:
    title: Optional[str] = None


@dataclass
class ChatMessage:
    role: Literal["user", "assistant", "system"]
    content: str | FileData | Component | FileDataDict | tuple | list
    metadata: MetadataDict | Metadata = field(default_factory=Metadata)
```


## **As input component**: {@html style_formatted_text(obj.preprocess.return_doc.doc)}
##### Your function should accept one of these types:

If `type` is `tuples` - 

```python
from gradio import Component

def predict(
	value: list[list[str | tuple[str, str] | Component | None]] | None
):
	...
```

If `type` is `messages` - 

```python
from gradio import MessageDict

def predict(value: list[MessageDict] | None):
    ...
```
<br>

## **As output component**: {@html style_formatted_text(obj.postprocess.parameter_doc[0].doc)}
##### Your function should return one of these types:

If `type` is `tuples` - 

```python
def predict(¬∑¬∑¬∑) -> list[list[str | tuple[str] | tuple[str, str] | None] | tuple] | None
	...	
	return value
```

If `type` is `messages` - 

from gradio import ChatMessage, MessageDict

```python
def predict(¬∑¬∑¬∑) - > list[MessageDict] | list[ChatMessage]:
    ...
```

<!--- Initialization -->
### Initialization
<ParamTable parameters={obj.parameters} />


{#if obj.string_shortcuts && obj.string_shortcuts.length > 0}
<!--- Shortcuts -->
### Shortcuts
<ShortcutTable shortcuts={obj.string_shortcuts} />
{/if}

### Examples

**Using Gradio Components Inside `gr.Chatbot`**

The `Chatbot` component supports using many of the core Gradio components (such as `gr.Image`, `gr.Plot`, `gr.Audio`, and `gr.HTML`) inside of the chatbot. Simply include one of these components in your list of tuples. Here's an example:

```py
import gradio as gr

def load():
    return [
        ("Here's an audio", gr.Audio("https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav")),
        ("Here's an video", gr.Video("https://github.com/gradio-app/gradio/raw/main/demo/video_component/files/world.mp4"))
    ]

with gr.Blocks() as demo:
    chatbot = gr.Chatbot()
    button = gr.Button("Load audio and video")
    button.click(load, None, chatbot)

demo.launch()
```

{#if obj.demos && obj.demos.length > 0}
<!--- Demos -->
### Demos 
<DemosSection demos={obj.demos} />
{/if}

{#if obj.fns && obj.fns.length > 0}
<!--- Event Listeners -->
### Event Listeners 
<FunctionsSection fns={obj.fns} event_listeners={true} />
{/if}

{#if obj.guides && obj.guides.length > 0}
<!--- Guides -->
### Guides
<GuidesSection guides={obj.guides}/>
{/if}
